{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDYSbZQXQGjF"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "\n",
        "Tecnológico de Monterrey\n",
        "\n",
        "Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "### **Actividad de la semana: Modelos basados en Árboles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k7wepYbUvx5"
      },
      "source": [
        "\n",
        "**Nombre y matrícula:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJvdRW_asVWr"
      },
      "source": [
        "# **PARTE - 1 - Bosque Aleatorio (Random Forest) - Clasificación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oLDgzdzq5szg"
      },
      "outputs": [],
      "source": [
        "# Importamos lo necesario para la actividad\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, learning_curve, cross_val_score, StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import make_scorer, recall_score, accuracy_score, precision_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "\n",
        "np.random.seed(17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gv02e0nI5ylj"
      },
      "outputs": [],
      "source": [
        "# Para esta actividad vamos a generar datos sintéticos para un problema de\n",
        "# clasificación binario utilizando \"make_classification\" de scikitlearn.\n",
        "\n",
        "\n",
        "# Recuerda consultar la documentación para mayor información:\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html\n",
        "\n",
        "\n",
        "# Utilizaremos los siguientes valores de los hiperparámetros de make_classification:\n",
        "# - n_samples: número de muestras o registros a generar.\n",
        "# - n_features: número total de características o variables de entrada X.\n",
        "# - n_informative: número de características informativas o independientes.\n",
        "# - n_redundant: número de características redundantes.\n",
        "# - weights: pesos para las clases [0,1]-->[Clase_Mayoritaria_Negativa(0), clase_minoritaria_positiva(1)].\n",
        "# - class_sep: separación entre clases (mayor valor --> clases más separables y menos complejo).\n",
        "# - flip_y: fracción de ejemplos cuya clase se cambia aleatoriamente (ruido), para hacerlo más complejo.\n",
        "# - random_state: semilla para reproducibilidad.\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=10_000,          # 10,000 registros\n",
        "    n_features=20,             # factores en total\n",
        "    n_informative=15,          # factores informativos o variables de entrada independientes\n",
        "    n_redundant=5,             # factores redundantes (dependientes). Para añadir complejidad usamos valor > 0\n",
        "    weights=[0.88, 0.12],      # Desbalance de clases: Mayoritaria clase 0; minoritaria clase 1\n",
        "    class_sep=1.0,             # Separación entre clases\n",
        "    n_classes=2,               # Dos clases\n",
        "    n_clusters_per_class=1,    # Para agregar complejidad adicional considera valores > 1\n",
        "    flip_y=0.01,              # Añadir algo de ruido. default 0.01\n",
        "    random_state=17,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QMhcUInh78C1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de registros generados: 10000\n",
            "Distribución de clases: target\n",
            "0    87.7%\n",
            "1    12.3%\n",
            "Name: proportion, dtype: object\n",
            "Cantidad de factores: 20\n"
          ]
        }
      ],
      "source": [
        "# A continuación transformamos el conjunto de datos para que ya\n",
        "# están escalados alrededor del cero y donde todas las variables\n",
        "# sean numéricas.\n",
        "\n",
        "# Escalamos las características para que estén en el mismo rango:\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Creamos un DataFrame para su mejor manejo\n",
        "feature_names = [f'feature_{i+1}' for i in range(20)]\n",
        "df = pd.DataFrame(X_scaled, columns=feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "print(f\"Total de registros generados: {len(df)}\")\n",
        "print(f\"Distribución de clases: {df['target'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'}\")\n",
        "print(f\"Cantidad de factores: {len(feature_names)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jkmFcmS-7rnP"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-2.975398e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.319283</td>\n",
              "      <td>-0.684822</td>\n",
              "      <td>0.004073</td>\n",
              "      <td>0.677250</td>\n",
              "      <td>3.687062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>7.526424e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.695898</td>\n",
              "      <td>-0.625902</td>\n",
              "      <td>0.032897</td>\n",
              "      <td>0.677990</td>\n",
              "      <td>3.586427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-1.200817e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.145038</td>\n",
              "      <td>-0.678332</td>\n",
              "      <td>-0.011665</td>\n",
              "      <td>0.652550</td>\n",
              "      <td>4.905356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-2.557954e-17</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.334555</td>\n",
              "      <td>-0.687072</td>\n",
              "      <td>0.003736</td>\n",
              "      <td>0.685287</td>\n",
              "      <td>3.593032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-1.136868e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.321957</td>\n",
              "      <td>-0.669080</td>\n",
              "      <td>-0.006064</td>\n",
              "      <td>0.664607</td>\n",
              "      <td>3.892569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_6</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-7.531753e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.909673</td>\n",
              "      <td>-0.672018</td>\n",
              "      <td>-0.008130</td>\n",
              "      <td>0.664904</td>\n",
              "      <td>4.121387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_7</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-3.552714e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.343465</td>\n",
              "      <td>-0.670030</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.675504</td>\n",
              "      <td>4.006125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_8</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-2.280842e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.595287</td>\n",
              "      <td>-0.664497</td>\n",
              "      <td>0.001492</td>\n",
              "      <td>0.678691</td>\n",
              "      <td>4.218665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_9</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.228528e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.178195</td>\n",
              "      <td>-0.669604</td>\n",
              "      <td>0.011517</td>\n",
              "      <td>0.674292</td>\n",
              "      <td>3.222102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_10</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-1.023182e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.792678</td>\n",
              "      <td>-0.656117</td>\n",
              "      <td>0.012811</td>\n",
              "      <td>0.683887</td>\n",
              "      <td>3.803196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_11</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>7.105427e-17</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.708944</td>\n",
              "      <td>-0.681193</td>\n",
              "      <td>-0.006515</td>\n",
              "      <td>0.671897</td>\n",
              "      <td>3.900616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_12</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-1.590195e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.590769</td>\n",
              "      <td>-0.673371</td>\n",
              "      <td>0.018082</td>\n",
              "      <td>0.674805</td>\n",
              "      <td>3.888525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_13</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-1.265477e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.531079</td>\n",
              "      <td>-0.686781</td>\n",
              "      <td>-0.011999</td>\n",
              "      <td>0.675688</td>\n",
              "      <td>3.820194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_14</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-2.104628e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.700766</td>\n",
              "      <td>-0.681774</td>\n",
              "      <td>-0.004282</td>\n",
              "      <td>0.676168</td>\n",
              "      <td>3.611966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_15</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>9.531931e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.983869</td>\n",
              "      <td>-0.681577</td>\n",
              "      <td>0.005401</td>\n",
              "      <td>0.676399</td>\n",
              "      <td>3.574353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_16</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-3.431921e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.750420</td>\n",
              "      <td>-0.680181</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.677618</td>\n",
              "      <td>3.537105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_17</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-6.274092e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.476568</td>\n",
              "      <td>-0.654400</td>\n",
              "      <td>0.005515</td>\n",
              "      <td>0.670779</td>\n",
              "      <td>5.059527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_18</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>2.017941e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.667382</td>\n",
              "      <td>-0.667150</td>\n",
              "      <td>-0.011120</td>\n",
              "      <td>0.673768</td>\n",
              "      <td>3.722115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_19</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-2.051337e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.952765</td>\n",
              "      <td>-0.672314</td>\n",
              "      <td>0.017275</td>\n",
              "      <td>0.671184</td>\n",
              "      <td>3.580861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_20</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>2.338041e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.122353</td>\n",
              "      <td>-0.666474</td>\n",
              "      <td>0.017883</td>\n",
              "      <td>0.668517</td>\n",
              "      <td>4.006657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.232000e-01</td>\n",
              "      <td>0.328683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              count          mean       std       min       25%       50%  \\\n",
              "feature_1   10000.0 -2.975398e-16  1.000050 -3.319283 -0.684822  0.004073   \n",
              "feature_2   10000.0  7.526424e-16  1.000050 -4.695898 -0.625902  0.032897   \n",
              "feature_3   10000.0 -1.200817e-15  1.000050 -4.145038 -0.678332 -0.011665   \n",
              "feature_4   10000.0 -2.557954e-17  1.000050 -4.334555 -0.687072  0.003736   \n",
              "feature_5   10000.0 -1.136868e-16  1.000050 -3.321957 -0.669080 -0.006064   \n",
              "feature_6   10000.0 -7.531753e-16  1.000050 -3.909673 -0.672018 -0.008130   \n",
              "feature_7   10000.0 -3.552714e-16  1.000050 -4.343465 -0.670030  0.000240   \n",
              "feature_8   10000.0 -2.280842e-16  1.000050 -3.595287 -0.664497  0.001492   \n",
              "feature_9   10000.0  1.228528e-15  1.000050 -4.178195 -0.669604  0.011517   \n",
              "feature_10  10000.0 -1.023182e-15  1.000050 -3.792678 -0.656117  0.012811   \n",
              "feature_11  10000.0  7.105427e-17  1.000050 -3.708944 -0.681193 -0.006515   \n",
              "feature_12  10000.0 -1.590195e-15  1.000050 -3.590769 -0.673371  0.018082   \n",
              "feature_13  10000.0 -1.265477e-15  1.000050 -3.531079 -0.686781 -0.011999   \n",
              "feature_14  10000.0 -2.104628e-15  1.000050 -3.700766 -0.681774 -0.004282   \n",
              "feature_15  10000.0  9.531931e-16  1.000050 -3.983869 -0.681577  0.005401   \n",
              "feature_16  10000.0 -3.431921e-16  1.000050 -3.750420 -0.680181  0.000287   \n",
              "feature_17  10000.0 -6.274092e-16  1.000050 -4.476568 -0.654400  0.005515   \n",
              "feature_18  10000.0  2.017941e-16  1.000050 -3.667382 -0.667150 -0.011120   \n",
              "feature_19  10000.0 -2.051337e-15  1.000050 -3.952765 -0.672314  0.017275   \n",
              "feature_20  10000.0  2.338041e-15  1.000050 -4.122353 -0.666474  0.017883   \n",
              "target      10000.0  1.232000e-01  0.328683  0.000000  0.000000  0.000000   \n",
              "\n",
              "                 75%       max  \n",
              "feature_1   0.677250  3.687062  \n",
              "feature_2   0.677990  3.586427  \n",
              "feature_3   0.652550  4.905356  \n",
              "feature_4   0.685287  3.593032  \n",
              "feature_5   0.664607  3.892569  \n",
              "feature_6   0.664904  4.121387  \n",
              "feature_7   0.675504  4.006125  \n",
              "feature_8   0.678691  4.218665  \n",
              "feature_9   0.674292  3.222102  \n",
              "feature_10  0.683887  3.803196  \n",
              "feature_11  0.671897  3.900616  \n",
              "feature_12  0.674805  3.888525  \n",
              "feature_13  0.675688  3.820194  \n",
              "feature_14  0.676168  3.611966  \n",
              "feature_15  0.676399  3.574353  \n",
              "feature_16  0.677618  3.537105  \n",
              "feature_17  0.670779  5.059527  \n",
              "feature_18  0.673768  3.722115  \n",
              "feature_19  0.671184  3.580861  \n",
              "feature_20  0.668517  4.006657  \n",
              "target      0.000000  1.000000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(df).describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIhubZHG8a-Y",
        "outputId": "b5596e14-1b80-46c3-89e3-ae99b2a8c484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del conjunto de entrenamiento: 8000 muestras\n",
            "Tamaño del conjunto de prueba: 2000 muestras\n"
          ]
        }
      ],
      "source": [
        "# Separamos las variables de entrada y la variable objetivo de salida:\n",
        "X = df.drop('target', axis=1).values\n",
        "y = df['target'].values\n",
        "\n",
        "# Dividimos el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
        "# Como vamos a utilizar Validación Cruzada, la partición será solamente\n",
        "# con los conjuntos de Entrenamiento y Prueba.\n",
        "# Además usamos \"stratify\" para mantener la proporción de clases en la partición.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, stratify=y)\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
        "print(f\"Tamaño del conjunto de prueba: {X_test.shape[0]} muestras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ItnzozIq8i9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Salidas del modelo Dummy con diferentes estrategias\n",
            "para calcular umbrales del modelo base (baseline):\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Estrategia: most_frequent\n",
            "Accuracy: 0.8769\n",
            "Recall: 0.0000\n",
            "Precision: 0.0000\n",
            "F1 Score: 0.0000\n",
            "Matriz de Confusión:\n",
            "[[1403    0]\n",
            " [ 197    0]]\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Estrategia: prior\n",
            "Accuracy: 0.8769\n",
            "Recall: 0.0000\n",
            "Precision: 0.0000\n",
            "F1 Score: 0.0000\n",
            "Matriz de Confusión:\n",
            "[[1403    0]\n",
            " [ 197    0]]\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Estrategia: stratified\n",
            "Accuracy: 0.8006\n",
            "Recall: 0.1015\n",
            "Precision: 0.1235\n",
            "F1 Score: 0.1114\n",
            "Matriz de Confusión:\n",
            "[[1261  142]\n",
            " [ 177   20]]\n",
            "------------------------------\n",
            "\n",
            "\n",
            "Estrategia: uniform\n",
            "Accuracy: 0.4856\n",
            "Recall: 0.4670\n",
            "Precision: 0.1136\n",
            "F1 Score: 0.1827\n",
            "Matriz de Confusión:\n",
            "[[685 718]\n",
            " [105  92]]\n",
            "------------------------------\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "c:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "# Obtengamos los siguientes resultados con la función Dummy,\n",
        "# con una partición provisional para el Dummy:\n",
        "\n",
        "Xt, Xv, yt, yv = train_test_split(X_train, y_train, test_size=0.2, random_state=17, stratify=y_train)\n",
        "\n",
        "estrategias = ['most_frequent','prior','stratified','uniform']\n",
        "\n",
        "print(\"Salidas del modelo Dummy con diferentes estrategias\")\n",
        "print(\"para calcular umbrales del modelo base (baseline):\")\n",
        "print(\"-\"*50)\n",
        "print(\"\\n\")\n",
        "\n",
        "for estrategia in estrategias:\n",
        "  dummy_clf = DummyClassifier(strategy=estrategia, random_state=17)\n",
        "  dummy_clf.fit(Xt, yt)\n",
        "  y_pred = dummy_clf.predict(Xv)\n",
        "\n",
        "  # Tabla para almacenar resultados\n",
        "  results = []\n",
        "\n",
        "  # \"pos_label\" indica la clase con respecto a la cual evaluar cada métrica.\n",
        "  acc = accuracy_score(yv, y_pred)\n",
        "  rec = recall_score(yv, y_pred, pos_label=1)\n",
        "  prec = precision_score(yv, y_pred, pos_label=1)\n",
        "  f1_sc = f1_score(yv, y_pred, pos_label=1)\n",
        "\n",
        "  results.append({'Accuracy': acc,\n",
        "                'Recall': rec,\n",
        "                'Precision': prec,\n",
        "                'F1 Score': f1_sc\n",
        "                })\n",
        "\n",
        "  print(f\"Estrategia: {estrategia}\")\n",
        "  print(f\"Accuracy: {acc:.4f}\")\n",
        "  print(f\"Recall: {rec:.4f}\")\n",
        "  print(f\"Precision: {prec:.4f}\")\n",
        "  print(f\"F1 Score: {f1_sc:.4f}\")\n",
        "\n",
        "  print(\"Matriz de Confusión:\")\n",
        "  cm = confusion_matrix(yv, y_pred)  # , normalize='true'\n",
        "  print(cm)\n",
        "  print(\"-\"*30)\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mK6SXmx-m71"
      },
      "source": [
        "## **Ejercicio - 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G99WdcMCbxo"
      },
      "source": [
        "### **Ejercicio 1a**\n",
        "\n",
        "**En la salida anterior se obtuvieron dos advertencias (warnings).**\n",
        "\n",
        "* **a) ¿A cuáles casos de las estrategias Dummy están asociadas esas advertencias?**\n",
        "\n",
        "A las estrategias 'most frequent' y 'prior'.\n",
        "\n",
        "* **b) Explica qué significan esas advertencias y relaciona la explicación con los valores de las matrices de confusión correspondientes.**\n",
        "\n",
        "Esta advertencia se debe a que no se predijeron valores de la clase positiva. Como se puede ver en las matrices de confusión, las columnas de la derecha están en 0 ambas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTAOZJ49-dOM"
      },
      "source": [
        "### **Ejercicio 1b**\n",
        "\n",
        "**Sabemos que si consideramos la métrica de la exactitud (accuracy) como nuestra métrica principal, el umbral del modelo base (baseline) sería del 87.7%. Sin embargo, como tenemos un problema de clases desbalanceadas debiéramos utilizar otra métrica que nos ayude a medir mejor el desempeño del modelo. Indica en cada uno de los siguientes incisos cuál sería el valor del modelo base que debiéramos utilizar, de acuerdo a la métrica que se indica:**\n",
        "\n",
        "* **a) Precision: La estrategia 'stratified' obtuvo un máximo de 12.3% de Precision, por lo que esa sería nuestro umbral** \n",
        "\n",
        "* **b) Recall: La estrategia 'uniform' ubtuvo un máximo de 48.2% de Recall, por lo que ese sería nuestro umbral**\n",
        "\n",
        "* **c) F1-Score: La estrategia 'uniform' ubtuvo un máximo de 18.2% de F1-Score, por lo que ese sería nuestro umbral**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sqh3yly-qu4"
      },
      "source": [
        "NOTA: La documentación de la función Dummy la puedes encontrar en la siguiente liga:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLWCrmnpse89"
      },
      "source": [
        "# **PARTE - 2 - XGBoost - Regressor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7Z7l2sTYuv"
      },
      "source": [
        "Para este ejercicio usaremos los datos llamados Bike-Sharing, en particular los del archivo \"day.csv\".\n",
        "\n",
        "La información de los datos y el archivo lo encuentras en la siguiente liga:\n",
        "\n",
        "https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset\n",
        "\n",
        "El archivo contiene información de la cantidad de bicicletas rentadas por día en la ciudad de Washington, D.C. a través de un servicio llamado \"Captial Bike Sharing (CBS)\", que les proporciona el gobierno municipal. Esta será nuestra variable objetivo a predecir. Los factores o variables de entrada a considerar son diversos, por ejemplo, la temperatura, humedad, día de la semana, días feriados, etc. Los datos se registraron durante los años 2011 y 2012.\n",
        "\n",
        "Puedes encontrar más información del problema en  https://github.com/jkelleman/rental-bike-sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiQoHszhY00K"
      },
      "source": [
        "En esta segunda parte no se te incluye el código. Con base a los ejercicios de muestra de esta semana y lo visto en semanas anteriores, deberás incluir el código correspondiente. Podrás incluir todas las celdas y código que consideres necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hKfUxLwodsZ2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Incluye en esta celda todas las librerías y paquetes que requieras\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "\n",
        "import shap\n",
        "from xgboost import XGBRegressor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLm-v3BQZc6C"
      },
      "source": [
        "## **Ejercicio - 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y--0_ZcqZrp6"
      },
      "source": [
        "* **Carga los datos del archivo \"day.csv\" en un DataFrame de Pandas y elimina las columnas \"instant\", \"dteday\", \"casual\" y \"registered\". Despliega los primeros renglones del DataFrame e indica la dimensión de los datos.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dmZZDfp3at7J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descripción estadística:\n",
            "            count         mean          std        min          25%  \\\n",
            "instant     731.0   366.000000   211.165812   1.000000   183.500000   \n",
            "season      731.0     2.496580     1.110807   1.000000     2.000000   \n",
            "yr          731.0     0.500684     0.500342   0.000000     0.000000   \n",
            "mnth        731.0     6.519836     3.451913   1.000000     4.000000   \n",
            "holiday     731.0     0.028728     0.167155   0.000000     0.000000   \n",
            "weekday     731.0     2.997264     2.004787   0.000000     1.000000   \n",
            "workingday  731.0     0.683995     0.465233   0.000000     0.000000   \n",
            "weathersit  731.0     1.395349     0.544894   1.000000     1.000000   \n",
            "temp        731.0     0.495385     0.183051   0.059130     0.337083   \n",
            "atemp       731.0     0.474354     0.162961   0.079070     0.337842   \n",
            "hum         731.0     0.627894     0.142429   0.000000     0.520000   \n",
            "windspeed   731.0     0.190486     0.077498   0.022392     0.134950   \n",
            "casual      731.0   848.176471   686.622488   2.000000   315.500000   \n",
            "registered  731.0  3656.172367  1560.256377  20.000000  2497.000000   \n",
            "cnt         731.0  4504.348837  1937.211452  22.000000  3152.000000   \n",
            "\n",
            "                    50%          75%          max  \n",
            "instant      366.000000   548.500000   731.000000  \n",
            "season         3.000000     3.000000     4.000000  \n",
            "yr             1.000000     1.000000     1.000000  \n",
            "mnth           7.000000    10.000000    12.000000  \n",
            "holiday        0.000000     0.000000     1.000000  \n",
            "weekday        3.000000     5.000000     6.000000  \n",
            "workingday     1.000000     1.000000     1.000000  \n",
            "weathersit     1.000000     2.000000     3.000000  \n",
            "temp           0.498333     0.655417     0.861667  \n",
            "atemp          0.486733     0.608602     0.840896  \n",
            "hum            0.626667     0.730209     0.972500  \n",
            "windspeed      0.180975     0.233214     0.507463  \n",
            "casual       713.000000  1096.000000  3410.000000  \n",
            "registered  3662.000000  4776.500000  6946.000000  \n",
            "cnt         4548.000000  5956.000000  8714.000000  \n",
            "Dimension de los datos: (731, 12)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.344167</td>\n",
              "      <td>0.363625</td>\n",
              "      <td>0.805833</td>\n",
              "      <td>0.160446</td>\n",
              "      <td>985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.363478</td>\n",
              "      <td>0.353739</td>\n",
              "      <td>0.696087</td>\n",
              "      <td>0.248539</td>\n",
              "      <td>801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.196364</td>\n",
              "      <td>0.189405</td>\n",
              "      <td>0.437273</td>\n",
              "      <td>0.248309</td>\n",
              "      <td>1349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.212122</td>\n",
              "      <td>0.590435</td>\n",
              "      <td>0.160296</td>\n",
              "      <td>1562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.226957</td>\n",
              "      <td>0.229270</td>\n",
              "      <td>0.436957</td>\n",
              "      <td>0.186900</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   season  yr  mnth  holiday  weekday  workingday  weathersit      temp  \\\n",
              "0       1   0     1        0        6           0           2  0.344167   \n",
              "1       1   0     1        0        0           0           2  0.363478   \n",
              "2       1   0     1        0        1           1           1  0.196364   \n",
              "3       1   0     1        0        2           1           1  0.200000   \n",
              "4       1   0     1        0        3           1           1  0.226957   \n",
              "\n",
              "      atemp       hum  windspeed   cnt  \n",
              "0  0.363625  0.805833   0.160446   985  \n",
              "1  0.353739  0.696087   0.248539   801  \n",
              "2  0.189405  0.437273   0.248309  1349  \n",
              "3  0.212122  0.590435   0.160296  1562  \n",
              "4  0.229270  0.436957   0.186900  1600  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ejercicio 2:\n",
        "\n",
        "# ************* Inicia sección para agregar tu código:**************************\n",
        "# Incluye todas las celdas que consideres necesarias.\n",
        "\n",
        "df = pd.read_csv(\"C:\\\\Coding\\\\Masters\\\\AI-ML\\\\Week 5\\\\day.csv\")\n",
        "\n",
        "print(f\"Descripción estadística:\\n{df.describe().T}\")\n",
        "\n",
        "df = df.drop(columns=['instant','dteday','casual','registered'])\n",
        "\n",
        "\n",
        "print(f\"Dimension de los datos: {df.shape}\")\n",
        "\n",
        "df.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_90FNhcb57J"
      },
      "source": [
        "## **Ejercicio - 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO8RVibGcDCh"
      },
      "source": [
        "### **Ejercicio 3a:**\n",
        "\n",
        "* **Justifica por qué se eliminaron las 4 variables indicadas en el ejercicio anterior.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "* Instant se elimina porque es un indice\n",
        "* Dteday se elimina porque es una fecha, no es relevante para el modelo\n",
        "* Casual y registered se eliminan porque son variables que suman la variable objetivo (cnt)\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YavL-4CPc8HQ"
      },
      "source": [
        "### **Ejercicio 3b:**\n",
        "\n",
        "* **Indica cuáles son las variables numéricas y cuáles las variables categóricas (nominales, ordinales, binarias). En particular indica cuál es la variable objetivo**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Las variables numéricas son temp, atemp, hum & windspeed.\n",
        "\n",
        "Las variables categóricas nominales son season, mnth, weekday.\n",
        "\n",
        "Las variables categóricas binarias son holiday, yr y workingday.\n",
        "\n",
        "Las variables categóricas ordinales son weathersit.\n",
        "\n",
        "La variable objetivo es cnt, el número de usuarios a los que se rentan las bicicletas y es lo que queremos optimizar.\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoE8lNuXlzue"
      },
      "source": [
        "## **Ejercicio - 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Z79GKTl6l1"
      },
      "source": [
        "* **Para simplificar la etapa del preproceasmiento de los datos observa que las variables numéricas ya están escaladas entre 0 y 1, por lo que no haremos transformación alguna. Sin embargo, en relación a las variables categóricas, verifica que todos los niveles de las variables nominales tengan al menos un 5% de información. De no ser así, agrupa los niveles de manera que se cumpla este criterio.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S4NXVO_pTIMJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categoría: season\n",
            "season\n",
            "3    25.7%\n",
            "2    25.2%\n",
            "1    24.8%\n",
            "4    24.4%\n",
            "Name: proportion, dtype: object\n",
            "------------------------------ \n",
            "\n",
            "\n",
            "Categoría: weathersit\n",
            "weathersit\n",
            "1    63.3%\n",
            "2    33.8%\n",
            "3     2.9%\n",
            "Name: proportion, dtype: object\n",
            "------------------------------ \n",
            "\n",
            "\n",
            "Categoría: mnth\n",
            "mnth\n",
            "1     8.5%\n",
            "3     8.5%\n",
            "7     8.5%\n",
            "5     8.5%\n",
            "12    8.5%\n",
            "10    8.5%\n",
            "8     8.5%\n",
            "4     8.2%\n",
            "9     8.2%\n",
            "6     8.2%\n",
            "11    8.2%\n",
            "2     7.8%\n",
            "Name: proportion, dtype: object\n",
            "------------------------------ \n",
            "\n",
            "\n",
            "Categoría: weekday\n",
            "weekday\n",
            "6    14.4%\n",
            "0    14.4%\n",
            "1    14.4%\n",
            "2    14.2%\n",
            "3    14.2%\n",
            "4    14.2%\n",
            "5    14.2%\n",
            "Name: proportion, dtype: object\n",
            "------------------------------ \n",
            "\n",
            "\n",
            "Categoría: holiday\n",
            "holiday\n",
            "0    97.1%\n",
            "1     2.9%\n",
            "Name: proportion, dtype: object\n",
            "------------------------------ \n",
            "\n",
            "\n",
            "Categoría: yr\n",
            "yr\n",
            "1    50.1%\n",
            "0    49.9%\n",
            "Name: proportion, dtype: object\n",
            "------------------------------ \n",
            "\n",
            "\n",
            "Categoría: workingday\n",
            "workingday\n",
            "1    68.4%\n",
            "0    31.6%\n",
            "Name: proportion, dtype: object\n",
            "------------------------------ \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ejercicio 4:\n",
        "\n",
        "# ************* Inicia sección para agregar tu código:**************************\n",
        "# Incluye todas las celdas que consideres necesarias.\n",
        "\n",
        "\n",
        "#Checking all categories have at least 5% of the data\n",
        "\n",
        "var_cat = ['season', 'weathersit', 'mnth', 'weekday', 'holiday', 'yr', 'workingday']\n",
        "\n",
        "for var in var_cat:\n",
        "    print(f\"Categoría: {var}\")\n",
        "    print(df[var].value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
        "    print(\"-\"*30, \"\\n\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Holiday y weathersit son las únicas variables que tienen categorías con menos del 5% de los datos.\n",
        "\n",
        "* Ya que la variable weathersit es ordinal, podemos cambiar los elementos de la clase 3 a la clase 2, ya que ambas representan condiciones climáticas adversas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribución de la variable weathersit después del cambio:\n",
            "weathersit\n",
            "1    63.3%\n",
            "2    36.7%\n",
            "Name: proportion, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Cambiar los elementos de la variable weathersit de 3 a 2\n",
        "df['weathersit'] = df['weathersit'].replace({3: 2})\n",
        "\n",
        "# Imprimir los porcentajes de la clase weathersit después del cambio\n",
        "print(\"Distribución de la variable weathersit después del cambio:\")\n",
        "print(df['weathersit'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH5sJn73pNFS"
      },
      "source": [
        "## **Ejercicio - 5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGKgRo-Go7ej"
      },
      "source": [
        "* **Particiona los datos en los conjuntos de entrenamiento y prueba con los porcentajes que consideres adecuado.**\n",
        "\n",
        "NOTA: Aplicarás más adelante validación cruzada, por ello separamos solo en dos conjuntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fRFjn7LJTIFh"
      },
      "outputs": [],
      "source": [
        "# Ejercicio 5:\n",
        "\n",
        "# ************* Inicia sección para agregar tu código:**************************\n",
        "# Incluye todas las celdas que consideres necesarias.\n",
        "\n",
        "\n",
        "# Definimos las variables predictoras y la variable objetivo\n",
        "X = df.drop(columns=['cnt'])\n",
        "y = df['cnt']\n",
        "\n",
        "# Separamos datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5pzkWGfpXSy"
      },
      "source": [
        "## **Ejercicio - 6**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4djR-TCFpY_S"
      },
      "source": [
        "* **Realiza una partición provisional del conjunto de entrenamiento anterior para obtener el valor del umbral del modelo base (baseline), con respecto a la métrica RMSE y al valor promedio de la variable de salida.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nAGsLdycTICJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE baseline (media como predicción): 1925.68\n"
          ]
        }
      ],
      "source": [
        "# Ejercicio 6:\n",
        "\n",
        "# ************* Inicia sección para agregar tu código:**************************\n",
        "# Incluye todas las celdas que consideres necesarias.\n",
        "\n",
        "# Particionamos los datos de entrenamiento\n",
        "X_t, X_v, y_t, y_v = train_test_split(X_train, y_train, test_size=0.2, random_state=17)\n",
        "\n",
        "baseline_value = y_t.mean()\n",
        "y_val_pred_baseline = np.full(shape=y_v.shape, fill_value=baseline_value, dtype=float)\n",
        "baseline_rmse = np.sqrt(((y_v - y_val_pred_baseline) ** 2).mean())\n",
        "\n",
        "print(f\"RMSE baseline (media como predicción): {baseline_rmse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDSAQF8iqh8h"
      },
      "source": [
        "## **Ejercicio - 7**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98jIApugqjs4"
      },
      "source": [
        "* **Usando la técnica de malla, validación cruzada y cuidando el filtrado de información, encuentra los mejores hiperparámetros del modelo XGBoost. Imprime el valor RMSE del mejor modelo encontrado.**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GjKiyFKvtwqV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
          ]
        },
        {
          "ename": "TerminatedWorkerError",
          "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nDetailed tracebacks of the workers should have been printed to stderr in the executor process if faulthandler was not disabled.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTerminatedWorkerError\u001b[39m                     Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=\u001b[33m'\u001b[39m\u001b[33mneg_root_mean_squared_error\u001b[39m\u001b[33m'\u001b[39m, cv=\u001b[32m3\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m2\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Entrenamos el modelo con GridSearchCV\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Obtenemos el mejor modelo\u001b[39;00m\n\u001b[32m     22\u001b[39m best_model = grid_search.best_estimator_\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Coding\\Masters\\AI-ML\\.venv\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[31mTerminatedWorkerError\u001b[39m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nDetailed tracebacks of the workers should have been printed to stderr in the executor process if faulthandler was not disabled."
          ]
        }
      ],
      "source": [
        "# Ejercicio 7:\n",
        "\n",
        "# ************* Inicia sección para agregar tu código:**************************\n",
        "# Incluye todas las celdas que consideres necesarias.\n",
        "\n",
        "\n",
        "# Definimos los hiperparámetros para GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "# Definimos el modelo\n",
        "model = XGBRegressor(random_state=17)\n",
        "# Configuramos GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=3, n_jobs=-1, verbose=2)\n",
        "# Entrenamos el modelo con GridSearchCV\n",
        "grid_search.fit(X_t, np.ravel(y_t))\n",
        "# Obtenemos el mejor modelo\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
        "# Realizamos predicciones con el mejor modelo\n",
        "y_pred_best = best_model.predict(X_v)\n",
        "# Evaluamos el mejor modelo\n",
        "mse_best = mean_squared_error(y_v, y_pred_best)\n",
        "rmse_best = np.sqrt(mse_best)\n",
        "print(f\"Mean Squared Error (MSE) del mejor modelo: {mse_best:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) del mejor modelo: {rmse_best:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt8H5PLasumX"
      },
      "source": [
        "## **Ejercicio - 8**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT6bfoqls2Am"
      },
      "source": [
        "* **Compara el valor RMSE del mejor modelo encontrado con respecto al valor del modelo base obtenido previamente. En particular, obtener la diferencia porcentual relativa del mejor modelo encontrado con respecto al modelo base. Incluye tu interpretación de dichos resultados.**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTCs4RuRTH-o"
      },
      "outputs": [],
      "source": [
        "# Ejercicio 8a:\n",
        "\n",
        "# ************* Inicia sección para agregar tu código:**************************\n",
        "# Incluye todas las celdas que consideres necesarias.\n",
        "\n",
        "\n",
        "None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2t4nZKht7YA"
      },
      "source": [
        "### **Ejercicio 8b:**\n",
        "\n",
        "* **Interpretación de los resultados obtenidos:**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tu respuesta.\n",
        "\n",
        "**None**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZpAB6b6uSp1"
      },
      "source": [
        "## **Ejercicio - 9**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lavZX1CjuV2F"
      },
      "source": [
        "### **Ejercicio 9a:**\n",
        "\n",
        "* **Usa el atributo \"feature_imortances_\" del mejor modelo encontrado para obtener los factores que influyen más en la predicción de la cantidad de bicicletas rentadas por día.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgbvT2V0TH7h"
      },
      "outputs": [],
      "source": [
        "# Ejercicio 9a:\n",
        "\n",
        "# ************* Inicia sección para agregar tu código:**************************\n",
        "# Incluye todas las celdas que consideres necesarias.\n",
        "\n",
        "\n",
        "None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7iB3SjPvnWe"
      },
      "source": [
        "### **Ejercicio 9b:**\n",
        "\n",
        "* **Usa la librería SHAP con el mejor modelo encontrado para obtener los factores que influyen más en la predicción de la cantidad de bicicletas rentadas por día.**\n",
        "\n",
        "NOTA: Puedes revisar la documentación correspondiente para el uso e interpretación de los gráficos de SHAP:\n",
        "\n",
        "https://github.com/shap/shap\n",
        "\n",
        "https://shap-readthedocs-io.translate.goog/en/latest/example_notebooks/api_examples/plots/beeswarm.html?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es&_x_tr_pto=tc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf78cH4QTH35"
      },
      "outputs": [],
      "source": [
        "# Ejercicio 9b:\n",
        "\n",
        "# ************* Inicia sección para agregar tu código:**************************\n",
        "# Incluye todas las celdas que consideres necesarias.\n",
        "\n",
        "\n",
        "None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9NMSjyNwdXy"
      },
      "source": [
        "### **Ejercicio 9c:**\n",
        "\n",
        "* **Incluye tu interpretación de los resultados obtenidos. En particular indica las coincidencias y diferencias entre ambos métodos de importancia de factores.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tu respuesta.\n",
        "\n",
        "**None**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6Q32efGw61s"
      },
      "source": [
        "## **Ejercicio - 10**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_qW8asPxMwq"
      },
      "source": [
        "Incluye tus conclusiones finales de la actividad.\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tu respuesta.\n",
        "\n",
        "**None**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TpR5Ae2xfkB"
      },
      "source": [
        "# **Fin de la Actividad de modelos basados en árboles**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aJvdRW_asVWr",
        "_mK6SXmx-m71",
        "CLWCrmnpse89",
        "OLm-v3BQZc6C",
        "u_90FNhcb57J",
        "HoE8lNuXlzue",
        "DH5sJn73pNFS",
        "H5pzkWGfpXSy",
        "BDSAQF8iqh8h",
        "zt8H5PLasumX",
        "oZpAB6b6uSp1",
        "I6Q32efGw61s"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
