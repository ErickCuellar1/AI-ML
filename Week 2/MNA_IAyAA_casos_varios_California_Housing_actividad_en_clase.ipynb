{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "####**Filtrado de datos (data leakage) / Pipeline / Curvas de Aprendizaje**\n",
        "\n",
        "Usaremos el modelo de Regresión Lineal para ejemplificar los diferentes pasos y técnicas que podemos aplicar en un problema de aprendizaje supervisado.\n",
        "\n",
        "Recuerda que no existen reglas generales, pero varias de las aquí utilizadas son muy utilizadas en general."
      ],
      "metadata": {
        "id": "iZH_9AwunsKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías básicas que estaremos requiriendo en la mayoría de las actividades.\n",
        "# Recuerda usar el # para documentar tu código dentro de estas celdas de Código.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns   # para un mejor despliegue de los gráficos\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "WgYhkVetDbmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usaremos los datos que nos proporciona Google-Colab para empezar a trabajar:\n",
        "#                       california_housing_train.csv\n",
        "#                       california_housing_test.csv\n",
        "#\n",
        "# Queremos accesar el archivo que está en la carpeta \"sample_data\" en la cual nos encontramos de manera\n",
        "# predeterminada y que podemos verificar con el siguiente comando que nos permite listar sus archivos\n",
        "# y directorios:\n",
        "\n",
        "!ls"
      ],
      "metadata": {
        "id": "Lm6QHJzj9WHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existen otras ligas con el mismo nombre, pero hay que tomar en cuenta que pueden ser algo diferentes. Algunas ligas son las siguientes:\n",
        "\n",
        "* Datos en sklearn:  \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html\n",
        "\n",
        "* Datos en Kaggle:  https://www.kaggle.com/datasets/camnugent/california-housing-prices\n",
        "\n",
        "* Datos en Keras:  https://keras.io/api/datasets/california_housing/\n",
        "\n",
        "entre otros...\n"
      ],
      "metadata": {
        "id": "5KvdimQV9blR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# La siguiente instrucción nos permite adentrarnos en dicha carpeta y de nuevo listamos lo que hay dentro de ella:\n",
        "\n",
        "%cd sample_data/\n",
        "\n",
        "!ls"
      ],
      "metadata": {
        "id": "Sq7zYLgoBcV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ruta del archivo:  /content/sample_data/california_housing_train.csv"
      ],
      "metadata": {
        "id": "DzkqC-ZO40qJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffesEiE3RAml"
      },
      "source": [
        "# En particular, los datos para el entrenamiento los encontramos en el archivo train, el cual procedemos a cargar:\n",
        "\n",
        "data = pd.read_csv(\"--- ruta del archivo de datos ---\", sep=\",\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De la documentación del problema (ver cualquier de las ligas dadas al inicio), sabemos que la variable de salida es el precio medio (mediana) de la casa en dólares estadounidenses, \"median_house_value\"."
      ],
      "metadata": {
        "id": "kkhimNeSexJZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygtqfXrjs_IG"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(6,5)})   # (ancho-columnas, altura-renglones) Ajustemos el tamaño de la ventana\n",
        "                                         # que desplegará los gráficos usando la librería de seaborn (sns)."
      ],
      "metadata": {
        "id": "QscEOyt2_nCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(data['longitude'], data['latitude'],'.');"
      ],
      "metadata": {
        "id": "QmFT4SyEU2WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.scatterplot(\n",
        "    data=data,\n",
        "    x=\"longitude\",\n",
        "    y=\"latitude\",\n",
        "    size=\"median_house_value\",\n",
        "    hue=\"median_house_value\",\n",
        "    palette=\"viridis\",\n",
        "    alpha=0.5,\n",
        ")\n",
        "plt.legend(title=\"median_house_value\", bbox_to_anchor=(1.05, 0.95), loc=\"upper left\")\n",
        "_ = plt.title(\"Median house value depending of\\n their spatial location\")"
      ],
      "metadata": {
        "id": "qehnp6BL_TVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(12,10)})\n",
        "\n",
        "fig, axes = plt.subplots(3, 3)    # definimos una ventana de 3x3 nichos para incluir en cada uno de ellos un gráfico.\n",
        "for k in range(0,9):\n",
        "  plt.subplot(3,3,k+1)     # los nichos para cada histograma se numeran iniciando en 1 y no en 0.\n",
        "  plt.hist(data[data.columns[k]], bins=20)     # datatrain.columns nos devuelve una lista con los nombres de las columnas.\n",
        "  plt.xlabel(data.columns[k])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XW3S8kW_qccK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "qrlfby2lIfAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Puedes nuevamente observar de esta tabla varias de las características que mencionamos previamente a partir de los histogramas.\n",
        "\n",
        "En particular, grafiquemos los datos geográficos dados por los factores latitud y longitud.\n",
        "\n",
        "Recuerda que debes observar siempre cada factor y decidir qué tipo de información particular podrías obtener de ahí."
      ],
      "metadata": {
        "id": "0BelKUNL3xtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Restricción:\n",
        "###Para un análisis rápido de los ejemplos que veremos a continuación, estaremos considerando solamente la variable de entrada \"total_bedrooms\"."
      ],
      "metadata": {
        "id": "6Jl6sg3IXQa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X1 =data[['total_bedrooms']]\n",
        "yy = data[['median_house_value']]"
      ],
      "metadata": {
        "id": "0r7lF8FUKAZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(6,4)})\n",
        "np.sqrt(X1).hist();"
      ],
      "metadata": {
        "id": "Do3IFv9YKjO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafiquemos \"total_bedrooms\" contra \"median_house_vale\":\n",
        "sns.set(rc={'figure.figsize':(7,8)})\n",
        "sns.scatterplot(data=data, x='total_bedrooms', y='median_house_value', alpha=0.1,)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KgrnhxmRB85J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Utilicemos varios modelos entre estas dos variables y vamos viendo qué conclusiones podemos ir obteniendo en cada caso."
      ],
      "metadata": {
        "id": "Dg6yvWZmbCO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modelo-1**"
      ],
      "metadata": {
        "id": "rNCF_CU4L0hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = LinearRegression()\n",
        "\n",
        "fit1 = m.fit(X1, yy)\n",
        "\n",
        "preds1 = fit1.predict(X1)\n",
        "rmse1 = np.sqrt(mean_squared_error(yy, preds1))\n",
        "\n",
        "print(\"RMSE: %.2f\" % (rmse1))"
      ],
      "metadata": {
        "id": "m5pSWXvvLMOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**¿Qué conclusiones podríamos obtener de este modelo?**\n",
        "\n",
        "###**¿Qué ajuste propones para mejorar el modelo?**"
      ],
      "metadata": {
        "id": "U5hPi9VuMxVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modelo-2**"
      ],
      "metadata": {
        "id": "qJhF1U1iMtl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = LinearRegression()\n",
        "\n",
        "X2 = np.sqrt(X1)\n",
        "\n",
        "fit2 = m.fit(X2, yy)\n",
        "\n",
        "preds2 = fit2.predict(X2)\n",
        "rmse2 = np.sqrt(mean_squared_error(yy, preds2))\n",
        "\n",
        "print(\"RMSE: %.2f\" % (rmse2))"
      ],
      "metadata": {
        "id": "PWihUn1BLMLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**¿Qué conclusiones podríamos obtener de este modelo?**\n",
        "\n",
        "###**¿Qué ajuste propones para seguir mejorando el modelo?**"
      ],
      "metadata": {
        "id": "OUEuJYd6OJ9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modelo-3**"
      ],
      "metadata": {
        "id": "x6iOJXktOLy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semilla = 11\n",
        "val_size = 0.2"
      ],
      "metadata": {
        "id": "FjFTtCo4yYYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = np.sqrt(X1)    # Observa que la transformación de los datos de entrada\n",
        "                    # es ANTES de la partición... ¿es esto correcto?\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X2, yy, test_size=val_size, random_state=semilla)   # partición\n",
        "\n",
        "\n",
        "m = LinearRegression()\n",
        "\n",
        "fit3 = m.fit(X_train, y_train)\n",
        "\n",
        "predsTrain = fit3.predict(X_train)\n",
        "rmseTrain = np.sqrt(mean_squared_error(y_train, predsTrain))\n",
        "\n",
        "predsVal3 = fit3.predict(X_val)\n",
        "rmseVal3 = np.sqrt(mean_squared_error(y_val, predsVal3))\n",
        "\n",
        "print(\"RMSE-Train: %.2f\" % (rmseTrain))\n",
        "print(\"RMSE-val: %.2f\" % (rmseVal3))"
      ],
      "metadata": {
        "id": "9XdQf-ouMT0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Está subentrenado el modelo?\n",
        "# Umbral de modelo base muy sencillo, pero no muy exacto.\n",
        "# Para una primera aproximación algo rústica del modelo base, se puede utilizar\n",
        "# la desviación estándar de la variable de salida en el conjunto de entrenamiento:\n",
        "y_train.std()"
      ],
      "metadata": {
        "id": "GOUoab26Bptc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**¿Qué conclusiones podríamos obtener de este modelo?**\n",
        "\n",
        "###**¿Qué otro ajuste propones para seguir mejorando el modelo?**"
      ],
      "metadata": {
        "id": "vajHCpRzPySk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###NOTA: Observa que al particionar el conjunto original de train en 80% y 20%, ya tenemos ahora el conjunto de entrenamiento y el de validación. El archivo restante que se encuentra en la carpeta del Google-Colab, llamado \"california_housing_test.csv\", será el conjunto de prueba, que usaremos al final, una vez que decidamos que terminamos el proceso de entrenamiento y que tenemos el mejor modelo."
      ],
      "metadata": {
        "id": "50J4WlbvecCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modelo-4**"
      ],
      "metadata": {
        "id": "IZqnyHmjPsC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X1, yy, test_size=val_size, random_state=semilla)   # partición\n",
        "\n",
        "X4_train = np.sqrt(X_train)    # Observa que la transformación de los datos de entrada ahora\n",
        "X4_val = np.sqrt(X_val)        # es DESPUÉS de la partición... ¿es esto correcto?\n",
        "\n",
        "\n",
        "\n",
        "m = LinearRegression()\n",
        "\n",
        "fit4 = m.fit(X4_train, y_train)\n",
        "\n",
        "predsTrain = fit4.predict(X4_train)\n",
        "rmseTrain = np.sqrt(mean_squared_error(y_train, predsTrain))\n",
        "\n",
        "predsVal4 = fit4.predict(X4_val)\n",
        "rmseVal4 = np.sqrt(mean_squared_error(y_val, predsVal4))\n",
        "\n",
        "print(\"RMSE-Train: %.2f\" % (rmseTrain))\n",
        "print(\"RMSE-Val: %.2f\" % (rmseVal4))"
      ],
      "metadata": {
        "id": "ucDMyuwZMTxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**¿Observa que obtuvimos el mismo resultado que el caso anterior? ¿Siempre deben ser iguales ambos resultados? En dado caso, ¿cuál debiera ser la manera correcta de proceder en general?**\n",
        "\n",
        "###**¿Qué otro ajuste propones para seguir mejorando el modelo?**"
      ],
      "metadata": {
        "id": "aS9n2CYiQtGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Un segundo modelo base con mejor aproximación.\n",
        "# Calculemos neuvamente el RMSE del modelo base, utilizando ahora el valor promedio\n",
        "# de los datos de entrenamiento y_train:\n",
        "y_train_mean = np.mean(y_train)\n",
        "\n",
        "# con este valor promedio obtengamos el RMSE usando ahora el conjunto y_val:\n",
        "rmseValBase = np.sqrt(mean_squared_error(y_val, np.full(y_val.shape, y_train_mean)))\n",
        "\n",
        "print(\"RMSE-Val-Base: %.2f\" % (rmseValBase))"
      ],
      "metadata": {
        "id": "nzqsQfAmSlbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modelo-5**"
      ],
      "metadata": {
        "id": "Nke9Awnlgj4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Supongamos que ahora también deseamos escalar los datos mediante la transformación (x-miu)/std.\n",
        "\n",
        "###¿Qué opinas de esta transformación, en este caso que solamente tenemos una variable de entrada?"
      ],
      "metadata": {
        "id": "_foa_4Zbmf4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "yZZPxLYroILT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X1, yy, test_size=val_size, random_state=semilla)\n",
        "\n",
        "X5_train = np.sqrt(X_train)\n",
        "X5_train = (X5_train - np.mean(X5_train, axis=0)) / np.std(X5_train)\n",
        "\n",
        "X5_val = np.sqrt(X_val)\n",
        "X5_val = (X5_val - np.mean(X5_val, axis=0)) / np.std(X5_val)\n",
        "\n",
        "\n",
        "\n",
        "m = LinearRegression()\n",
        "\n",
        "fit5 = m.fit(X5_train, y_train)\n",
        "\n",
        "predsTrain = fit5.predict(X5_train)\n",
        "rmseTrain = np.sqrt(mean_squared_error(y_train, predsTrain))\n",
        "\n",
        "predsVal5 = fit5.predict(X5_val)\n",
        "rmseVal5 = np.sqrt(mean_squared_error(y_val, predsVal5))\n",
        "\n",
        "print(\"RMSE-Train: %.2f\" % (rmseTrain))\n",
        "print(\"RMSE-Val: %.2f\\n\" % (rmseVal5))"
      ],
      "metadata": {
        "id": "C1AVr9OeoIIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**¿Qué conclusiones podríamos obtener de este modelo?**\n",
        "\n",
        "###**¿Qué otro ajuste propones para seguir mejorando el modelo?**"
      ],
      "metadata": {
        "id": "V70j-Sogi1GF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modelo-6: Usando Pipelines para evitar el filtrado de información (data leakage)**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h0k2RjCVj9RZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Veamos a continuación una manera más adecuada de llevar a cabo las transformaciones mediante el uso de la clase Pipeline de scikit-learn.\n",
        "\n",
        "###La clase Pipeline nos permitirá encapsular una serie de transformaciones para llevar a cabo el entrenamiento de un modelo, evitando el filtrado de información de una manera más amigable."
      ],
      "metadata": {
        "id": "RUtu4mVOpAYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "WOZlsPCYoICx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X1, yy, test_size=val_size, random_state=semilla)\n",
        "\n",
        "# Transformaciones que aplicaremos a los factores numéricos de entrada...\n",
        "# ¿es importante el orden de estas transformaciones?:\n",
        "num_pipeline = Pipeline(steps = [('impMediana', SimpleImputer(strategy='median')),\n",
        "                                 ('sqrt', FunctionTransformer(np.sqrt)),\n",
        "                                 ('escalaNum', StandardScaler())])\n",
        "\n",
        "# Identificamos las variables numéricas de entrada a las cuales aplicaremos las transformaciones definidas:\n",
        "num_pipeline_nombres = ['total_bedrooms']\n",
        "\n",
        "\n",
        "# Conjuntamos variables y transformaciones a aplicar y el resto (en caso de existir) las dejamos igual:\n",
        "columnasTransformer = ColumnTransformer(transformers = [('vars_num_pipeline', num_pipeline, num_pipeline_nombres)\n",
        "                                                        ],\n",
        "                                        remainder='passthrough')\n",
        "\n",
        "\n",
        "# Aplicamos las transformaciones al conjunto de entrenamiento:\n",
        "XtrainFit = columnasTransformer.fit(X_train)   # Conjunta todos los procesos definidos a cada variable del conjunto\n",
        "                                               # de entrenamiento para evitar el filtrado de información.\n",
        "\n",
        "XtrainTransf = XtrainFit.transform(X_train)    # y ahora aplicamos dichas transformaciones al conjunto de entrenamiento,\n",
        "XvalTransf  =  XtrainFit.transform(X_val)      # y también al conjunto de validación (con la información de los datos\n",
        "                                               # de Train)... este paso es lo que evita el filtrado de información\n",
        "                                               # al llevar a cabo las transformaciones.\n",
        "\n",
        "\n",
        "\n",
        "# Modelo de aprendizaje automático a entrenar:\n",
        "m = LinearRegression()\n",
        "\n",
        "# Entrenamos el modelo con los datos de entrenamiento:\n",
        "fit6 = m.fit(XtrainTransf, y_train)\n",
        "\n",
        "# Y obtenemos las predicciones:\n",
        "predstrain = fit6.predict(XtrainTransf)\n",
        "rmseTrain6 = np.sqrt(mean_squared_error(y_train, predstrain))\n",
        "\n",
        "predsval6 = fit6.predict(XvalTransf)\n",
        "rmseVal6 = np.sqrt(mean_squared_error(y_val, predsval6))\n",
        "\n",
        "print(\"RMSE-Train: %.2f\" % (rmseTrain6))\n",
        "print(\"RMSE-Val: %.2f\" % (rmseVal6))\n"
      ],
      "metadata": {
        "id": "QrZ-wgwroH_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Curvas de Aprendizaje**"
      ],
      "metadata": {
        "id": "NuxSt-gU91AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import RepeatedKFold"
      ],
      "metadata": {
        "id": "R3RF0k8k2jun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modeloLR = LinearRegression()\n",
        "\n",
        "XtvTransf = XtrainFit.transform(X1)   # Como usaremos Cross-Validation, usamos los conjuntos\n",
        "                                      # Train inicial que llamamos X1 y sus valores reales yy,\n",
        "                                      # es decir, aquí no usamos los datos de la partición directa\n",
        "                                      # ya que el método de Cross-Validation realizará internamente\n",
        "                                      # la partición en Train y Validation.\n",
        "\n",
        "# En el intervalo de 0.1 a 1.0, se seleccionan 20 puntos igualmente espaciados.\n",
        "# Representarán el porcentaje de datos que se utilizarán para entrenar al calcular\n",
        "# las curvas de aprendizaje con validación-cruzada:\n",
        "delta_train_sz = np.linspace(0.1, 1.0, 20)\n",
        "\n",
        "cvLR = RepeatedKFold(n_splits=10, n_repeats=5, random_state=semilla)\n",
        "\n",
        "train_sizes, train_scores, valid_scores = learning_curve(estimator=modeloLR,\n",
        "                                                        X=XtvTransf,\n",
        "                                                        y=yy,\n",
        "                                                        cv=cvLR,\n",
        "                                                        train_sizes=delta_train_sz,\n",
        "                                                        scoring='neg_root_mean_squared_error')\n",
        "\n",
        "\n",
        "\n",
        "# Obtengamos la gráfica de las curvas de aprendizaje\n",
        "# cuando se incrementa el tamaño de la muestra:\n",
        "\n",
        "train_mean = -np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "valid_mean = -np.mean(valid_scores, axis=1)\n",
        "valid_std = np.std(valid_scores, axis=1)\n",
        "\n",
        "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training')\n",
        "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
        "\n",
        "plt.plot(train_sizes, valid_mean, color='red', marker='o', markersize=5, label='Validation')\n",
        "plt.fill_between(train_sizes, valid_mean + valid_std, valid_mean - valid_std, alpha=0.15, color='red')\n",
        "\n",
        "plt.title('Función learning_curve()')\n",
        "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
        "plt.ylabel('RMSE')\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WJggNLrS2uHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_mean  # el último valor sería el del desempeño final con el conjunto de validación"
      ],
      "metadata": {
        "id": "fCTHODNuPDyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consulta la documentación correspondiente:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n"
      ],
      "metadata": {
        "id": "rW6vmZoy_Jzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modelo final con el conjunto de Prueba (Test)**"
      ],
      "metadata": {
        "id": "h52Mky9_pihG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datatest = pd.read_csv(\"california_housing_test.csv\", sep=\",\")   # cargamos los datos de la carpeta del Google-Colab, observa que\n",
        "                                                                 # hasta este momento no se habían usado estos datos.\n",
        "datatest.shape"
      ],
      "metadata": {
        "id": "1qZmU4nAmEKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest =datatest[['total_bedrooms']]\n",
        "ytest = datatest[['median_house_value']]"
      ],
      "metadata": {
        "id": "f0Pte8hNp4fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mf = LinearRegression()\n",
        "\n",
        "XtvTransf = XtrainFit.transform(X1)   # Observa que al obtener el entrenamiento final, usamos los datos tanto de Train como de Validation X1,\n",
        "                                      # esto permitirá todavía usar una mayor cantidad de información para aprender mejor. Sin embargo,\n",
        "                                      # seguimos usando la información que se obtuvo en el entrenamiento (XtrainFit) en el que solo se usó\n",
        "                                      # el conjunto de Train, para evitar el filtrado de información.\n",
        "                                      # Esta parte es opcional y se puede seguir usando solo el conjunto de entrenamiento,\n",
        "                                      # pero en general se recomienda al obtener el desempeño con el conjunto de Test,\n",
        "                                      # utilizar el conjunto completo de Train y Validación, PERO con el modelo en el que\n",
        "                                      # se entrenó SOLO con Train.\n",
        "\n",
        "XtestTransf  =  XtrainFit.transform(Xtest)\n",
        "\n",
        "fitf = mf.fit(XtvTransf, yy)\n",
        "\n",
        "predsTVf = fitf.predict(XtvTransf)\n",
        "rmseTVf = np.sqrt(mean_squared_error(yy, predsTVf))\n",
        "\n",
        "predsTestf = fitf.predict(XtestTransf)\n",
        "rmseTestf = np.sqrt(mean_squared_error(ytest, predsTestf))\n",
        "\n",
        "print(\"RMSE-TrainVal: %.2f\" % (rmseTVf))\n",
        "print(\"RMSE-Test: %.2f\" % (rmseTestf))"
      ],
      "metadata": {
        "id": "JtsL3V60qKop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Resumen de los diferentes modelos:\")\n",
        "print(\"\\tModelo1\\t\\tModelo2\\t\\tModelo3\\t\\tModelo4\\t\\tModelo5\\t\\tModelo6\\t\\tModeloF\")\n",
        "\n",
        "print(\"RMSE:  %.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t%.2f\\t\" % (rmse1, rmse2, rmseVal3, rmseVal4, rmseVal5, rmseVal6, rmseTestf) )\n",
        "\n"
      ],
      "metadata": {
        "id": "Iibl93BUu6Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Conclusiones finales:**\n",
        "\n",
        "### **...**"
      ],
      "metadata": {
        "id": "Ip2Jkr2bV98C"
      }
    }
  ]
}